Creating RL model...
Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Starting RL training for 100000 steps...
step: [92m168 / None[0m
Traceback (most recent call last):
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 406, in <module>
    model_path = train_rl(usr_args)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 356, in train_rl
    ppo_model.learn(
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 132, in step
    obs = self.task_env.get_obs()
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/_base_task.py", line 497, in get_obs
    pkl_dic["pointcloud"] = self.cameras.get_pcd(self.data_type.get("conbine", False))
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/camera/camera.py", line 580, in get_pcd
    pcd_array, index = fps(combined_pcd[:, :3], self.pcd_down_sample_num)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/camera/camera.py", line 26, in fps
    sampled_points = sampled_points.cpu().numpy()
KeyboardInterrupt
Traceback (most recent call last):
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 406, in <module>
    model_path = train_rl(usr_args)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 356, in train_rl
    ppo_model.learn(
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 222, in step
    return self.step_wait()
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 59, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]
  File "/home/tao/anaconda3/envs/RoboTwin/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/script/residual_train.py", line 132, in step
    obs = self.task_env.get_obs()
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/_base_task.py", line 497, in get_obs
    pkl_dic["pointcloud"] = self.cameras.get_pcd(self.data_type.get("conbine", False))
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/camera/camera.py", line 580, in get_pcd
    pcd_array, index = fps(combined_pcd[:, :3], self.pcd_down_sample_num)
  File "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/./envs/camera/camera.py", line 26, in fps
    sampled_points = sampled_points.cpu().numpy()
KeyboardInterrupt
